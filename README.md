# Machine Learning 101
This repo is my own personal guide to machine learning and contains knowledge from a variety of courses, blog posts and research papers that I have encountered that have been useful to me on my journey to becoming a Machine Learning Engineer. A detailed list of these links can be found at the bottom of this page.

## Usage/License
There isn't one! Please feel free to use these notes and code templates for your own products, everything here is free to utilise as you see fit :)

The majority of these notes and findings will be placed within the wiki, please pick the appropriate link from the table of contents below to navigate to the area of your choice.

### Coding Language & Libraries Used
All coding templates are written in Python 3.6 and the IDE used to create them was using Anaconda's Spyder, you can download Anaconda [here](https://www.anaconda.com/download/).

The Machine Learning models are coded using the following libraries: Scikit-learn, NumPy, Matplotlib and Pandas.

The Deep Learning models are coded using the following libraries: Tensorflow, Keras, PyTorch. The Supervised models used Keras & Unsupervised use PyTorch.

The Computer Vision models are coded using the following libraries: OpenCV for face recognition and smile detection, PyTorch for Object Detection & GANs.

The Artificial Intelligence models are coded using the following libraries: PyTorch for all models.

The Natural Language Processing models are coded using the following libraries: Tensorflow.

## Table of Contents
The sections consist of: Machine Learning, Deep Learning, Computer Vision, Artificial Intelligence, Natural Language Processing. These are split into multiple subsections that link to wiki pages for further information.

### Machine Learning
* [Data Preprocessing](https://github.com/Achronus/Machine-Learning-101/wiki/Data-Preprocessing)
* [Regression Models](https://github.com/Achronus/Machine-Learning-101/wiki/Regression-Models)
* [Classification Models](https://github.com/Achronus/Machine-Learning-101/wiki/Classification-Models)
* [Clustering Models](https://github.com/Achronus/Machine-Learning-101/wiki/Clustering-Models)
* [Association Rule Learning](https://github.com/Achronus/Machine-Learning-101/wiki/Association-Rule-Learning)
* [Reinforcement Learning](https://github.com/Achronus/Machine-Learning-101/wiki/Reinforcement-Learning)
* [Dimensionality Reduction](https://github.com/Achronus/Machine-Learning-101/wiki/Dimensionality-Reduction)
* [Model Selection](https://github.com/Achronus/Machine-Learning-101/wiki/Model-Selection)
* [XGBoost](https://github.com/Achronus/Machine-Learning-101/wiki/XGBoost)

### Deep Learning
* [Supervised Deep Learning Models](https://github.com/Achronus/Machine-Learning-101/wiki/Types-of-Deep-Learning)
  * [Artificial Neural Networks (ANN)](https://github.com/Achronus/Machine-Learning-101/wiki/Artificial-Neural-Networks-(ANN))
  * [Convolutional Neural Networks (CNN)](https://github.com/Achronus/Machine-Learning-101/wiki/Convolutional-Neural-Networks-(CNN))
  * [Recurrent Neural Networks (RNN)](https://github.com/Achronus/Machine-Learning-101/wiki/Recurrent-Neural-Networks-(RNN))

* [Unsupervised Deep Learning Models](https://github.com/Achronus/Machine-Learning-101/wiki/Types-of-Deep-Learning)
  * [Self Organizing Maps (SOM)](https://github.com/Achronus/Machine-Learning-101/wiki/Self-Organizing-Maps-(SOM))
  * [Boltzmann Machines (BM)](https://github.com/Achronus/Machine-Learning-101/wiki/Boltzmann-Machines-(BM))
  * [AutoEncoders (AE)](https://github.com/Achronus/Machine-Learning-101/wiki/AutoEncoders-(AE))

### Computer Vision
* [Face Recognition](https://github.com/Achronus/Machine-Learning-101/wiki/Face-Recognition)
* [Object Detection](https://github.com/Achronus/Machine-Learning-101/wiki/Object-Detection)
* [Generative Adversarial Networks (GANs)](https://github.com/Achronus/Machine-Learning-101/wiki/Generative-Adversarial-Networks-(GANs))

### Artificial Intelligence
* [Q-Learning](https://github.com/Achronus/Machine-Learning-101/wiki/Q-Learning)
* [Deep Q-Learning](https://github.com/Achronus/Machine-Learning-101/wiki/Deep-Q-Learning)
* [Deep Convolutional Q-Learning](https://github.com/Achronus/Machine-Learning-101/wiki/Deep-Convolutional-Q-Learning)
* [Asynchronous Advantage Actor-Critic (A3C)](https://github.com/Achronus/Machine-Learning-101/wiki/Asynchronous-Advantage-Actor-Critic-(A3C))

### Natural Language Processing
* [Deep Natural Language Processing](https://github.com/Achronus/Machine-Learning-101/wiki/Deep-Natural-Language-Processing)

## References
Here is the list of references for the information within this repo.

### Courses
I highly recommend these courses and I just want to say a huge thank you to the SuperDataScience Team (Kirill Eremenko & Hadelin de Ponteves) for making these incredible courses. All courses come with an intuitive understanding and coding examples for each model.

* [Machine Learning A-Z](https://www.udemy.com/machinelearning/)
* [Deep Learning A-Z](https://www.udemy.com/deeplearning/)
* [Deep Learning & Computer Vision A-Z](https://www.udemy.com/computer-vision-a-z/)
* [Artificial Intelligence A-Z](https://www.udemy.com/artificial-intelligence-az/)
* [Deep Learning & Natural Language Processing A-Z](https://www.udemy.com/chatbot/)

### Blog Posts
Thank you to all writers of the blog posts that are linked within this section, these have been a massive help to understanding core concepts of the Machine Learning world.

#### Machine Learning
* [Feature Scaling](https://sebastianraschka.com/Articles/2014_about_feature_scaling.html)
* [Gradient Descent](https://iamtrask.github.io/2015/07/27/python-network-part2/)
* [Overfitting](https://elitedatascience.com/overfitting-in-machine-learning)
* [Bias-Variance Tradeoff](https://elitedatascience.com/bias-variance-tradeoff)

#### Deep Learning
* [Cross-Entropy Loss](https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/)
* [Understanding Convolutional Neural Networks (CNNs)](https://adeshpande3.github.io/adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html)
* [Understanding Long Short-Term Memory (LSTM) Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
* [Attention and Augmented Recurrent Neural Networks](https://distill.pub/2016/augmented-rnns/)
* [AutoEncoders](https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/)
* [AutoEncoders in Keras](https://blog.keras.io/building-autoencoders-in-keras.html)
* [Brief Overview of Sparse AutoEncoders](http://www.ericlwilkinson.com/blog/2014/11/19/deep-learning-sparse-autoencoders)
* [Deep Learning Tutorial - Sparse Autoencoder](http://mccormickml.com/2014/05/30/deep-learning-tutorial-sparse-autoencoder/)

#### Computer Vision
* [Generative Adversarial Networks (GANs)](https://hackernoon.com/how-do-gans-intuitively-work-2dda07f247a1)

#### Artificial Intelligence
* [Simple Reinforcement Learning with Tensorflow: Q-Learning](https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0)
* [A3C Implementation](https://jaromiru.com/2017/03/26/lets-make-an-a3c-implementation/)
* [A3C Theory](https://jaromiru.com/2017/02/16/lets-make-an-a3c-theory/)
* [Simple Reinforcement Learning with Tensorflow: A3C](https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-8-asynchronous-actor-critic-agents-a3c-c88f72a5e9f2)

### Research Papers

#### Deep Learning
* [Introduction to Convolutional Neural Networks](https://acius.co.uk/wp-content/themes/acius/machine_learning/research_papers/cnn.pdf)
* [Max Pooling](https://acius.co.uk/wp-content/themes/acius/machine_learning/research_papers/maxpooling.pdf)
* [Contrastive Divergence](https://www.cs.toronto.edu/~hinton/absps/fastnc.pdf)
* [Adam: A Method for Stochastic Optimization](https://arxiv.org/pdf/1412.6980.pdf)
* [Reducing Dimensionality of Data with Neural Networks](https://www.cs.toronto.edu/~hinton/science.pdf)
* [Deconvolutional Networks](http://www.matthewzeiler.com/wp-content/uploads/2017/07/iccv2011.pdf)
* [Denoising Autoencoders](https://www.iro.umontreal.ca/~vincentp/Publications/denoising_autoencoders_tr1316.pdf)
* [Contractive Auto-Encoders: Explicit Invariance During Feature Extraction](http://www.icml-2011.org/papers/455_icmlpaper.pdf)
* [Stacked Denoising Autoencoders](http://www.jmlr.org/papers/volume11/vincent10a/vincent10a.pdf)
* [Deep Boltzmann Machines](http://www.utstat.toronto.edu/~rsalakhu/papers/dbm.pdf)
* [Energy-Based Learning](http://yann.lecun.com/exdb/publis/pdf/lecun-06.pdf)
* [An Introduction to Restricted Boltzmann Machines](https://acius.co.uk/wp-content/themes/acius/machine_learning/research_papers/restricted_boltzmann_machines.pdf)
* [Greedy Layer-Wise Training of Deep Networks](http://www.iro.umontreal.ca/~lisa/pointeurs/BengioNips2006All.pdf)
* [The Wake-sleep Algorithm for Unsupervised Neural Networks](http://www.cs.toronto.edu/~fritz/absps/ws.pdf)
* [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](http://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf)

#### Computer Vision
* [Single Shot MultiBox Detector (SSD)](https://www.cs.unc.edu/~wliu/papers/ssd.pdf)
* [A General Framework for Object Detection](https://acius.co.uk/wp-content/themes/acius/machine_learning/research_papers/face_detection.pdf)
* [Boosting Image Retrieval](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.136.2419&rep=rep1&type=pdf)

#### Artificial Intelligence
* [Markov Decision Processes: Concepts and Algorithms](https://pdfs.semanticscholar.org/968b/ab782e52faf0f7957ca0f38b9e9078454afe.pdf)
* [Learning to Predict by the Methods of Temporal Differences](https://link.springer.com/content/pdf/10.1023%2FA%3A1022633531479.pdf)
* [Prioritized Experience Replay](https://arxiv.org/pdf/1511.05952.pdf)
* [Adaptive Îµ-greedy Exploration in Reinforcement Learning Based on Value Differences](http://www.tokic.com/www/tokicm/publikationen/papers/AdaptiveEpsilonGreedyExploration.pdf)
* [Asynchronous Methods for Deep Reinforcement Learning](https://arxiv.org/pdf/1602.01783.pdf)
* [High-Dimensional Continuous Control Using Generalized Advantage Estimation](https://arxiv.org/pdf/1506.02438.pdf)

#### NLP
* [Effective Approaches to Attention-based Neural Machine Translation](http://aclweb.org/anthology/D15-1166)

## Additional Resources
Here are a few websites that have free datasets that can be used in your own Machine Learning models.

* [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/index.php) - A website home to over 400 datasets for use within the Machine Learning community.
* [Kaggle Datasets](https://www.kaggle.com/datasets) - Kaggle is an incredible website that brings the Data Scientists community together.
* [Grouplens Movie Quotes](https://grouplens.org/datasets/movielens/) - This dataset is used within the Deep Learning Boltzmann Machine & AutoEncoder models.
* [PASCAL Visual Object Classes](http://host.robots.ox.ac.uk/pascal/VOC/) - This dataset is used within the Computer Vision object detection section.
